gpu: 0
train_data_path: './data/stratified_100.csv'
k_folds: 5
wandb_on: False
use_prompt: True
save_best_model: False

model:
  path: './models/Meta-Llama-3.2-1B'
  version: '3.2'
  num_parameters: '1B'

checkpoint_dir: './checkpoints/'
prompt_path: './prompts/fine_tune_holistic.txt'

training_strategy: 'last_layer_only'
epochs: 1
batch_size: 2
max_len: 768

learning_rate:
  last_layer_only: 5e-5
  all_layers: 2e-5
  top_n_layers: 5e-5
  prompt_tuning: 2e-3

patience: 5
